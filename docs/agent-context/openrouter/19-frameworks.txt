Frameworks
You can find a few examples of using OpenRouter with other frameworks in this Github repository. Here are some examples:

Using OpenAI SDK
Using npm i openai: github.

Tip: You can also use Grit to automatically migrate your code. Simply run npx @getgrit/launcher openrouter.
Using pip install openai: github.

typescript
python

Copy
import OpenAI from "openai"

const openai = new OpenAI({
  baseURL: "https://openrouter.ai/api/v1",
  apiKey: $OPENROUTER_API_KEY,
  defaultHeaders: {
    "HTTP-Referer": $YOUR_SITE_URL, // Optional, for including your app on openrouter.ai rankings.
      "X-Title": $YOUR_SITE_NAME, // Optional. Shows in rankings on openrouter.ai.
  },
})

async function main() {
  const completion = await openai.chat.completions.create({
    model: "openai/gpt-4o",
    messages: [
      { role: "user", content: "Say this is a test" }
    ],
  })

  console.log(completion.choices[0].message)
}

main()
Using LangChain
Using LangChain for Python: github

Using LangChain.js: github

Using Streamlit: github

typescript
python

Copy
const chat = new ChatOpenAI({
  modelName: "anthropic/claude-3.5-sonnet",
  temperature: 0.8,
  streaming: true,
  openAIApiKey: $OPENROUTER_API_KEY,
}, {
  basePath: $OPENROUTER_BASE_URL + "/api/v1",
  baseOptions: {
    headers: {
      "HTTP-Referer": "https://yourapp.com/", // Optional, for including your app on openrouter.ai rankings.
        "X-Title": "Langchain.js Testing", // Optional. Shows in rankings on openrouter.ai.
    },
  },
});
Using PydanticAI
PydanticAI provides a high-level interface for working with various LLM providers, including OpenRouter.

Installation
bash

pip install 'pydantic-ai-slim[openai]'
Configuration
You can use OpenRouter with PydanticAI through its OpenAI-compatible interface:

python

from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel

model = OpenAIModel(
    'anthropic/claude-3.5-sonnet',  # or any other OpenRouter model
    base_url='https://openrouter.ai/api/v1',
    api_key='sk-or-...',
)

agent = Agent(model)
result = await agent.run("What is the meaning of life?")
print(result)
For more details about using PydanticAI with OpenRouter, see the PydanticAI documentation.

Vercel AI SDK
You can use the Vercel AI SDK to integrate OpenRouter with your Next.js app. To get started, install @openrouter/ai-sdk-provider:

bash

npm install @openrouter/ai-sdk-provider
And then you can use streamText() API to stream text from OpenRouter.

typescript

import { createOpenRouter } from '@openrouter/ai-sdk-provider';
import { streamText } from 'ai';
import { z } from 'zod';

export const getLasagnaRecipe = async (modelName: string) => {
  const openrouter = createOpenRouter({
    apiKey: process.env.OPENROUTER_API_KEY,
  });

  const result = await streamText({
    model: openrouter(modelName),
    prompt: 'Write a vegetarian lasagna recipe for 4 people.',
  });
  return result.toAIStreamResponse();
};

export const getWeather = async (modelName: string) => {
  const openrouter = createOpenRouter({
    apiKey: process.env.OPENROUTER_API_KEY,
  });

  const result = await streamText({
    model: openrouter(modelName),
    prompt: 'What is the weather in San Francisco, CA in Fahrenheit?',
    tools: {
      getCurrentWeather: {
        description: 'Get the current weather in a given location',
        parameters: z.object({
          location: z
            .string()
            .describe('The city and state, e.g. San Francisco, CA'),
          unit: z.enum(['celsius', 'fahrenheit']).optional(),
        }),
        execute: async ({ location, unit = 'celsius' }) => {
          // Mock response for the weather
          const weatherData = {
            'Boston, MA': {
              celsius: '15째C',
              fahrenheit: '59째F',
            },
            'San Francisco, CA': {
              celsius: '18째C',
              fahrenheit: '64째F',
            },
          };

          const weather = weatherData[location];
          if (!weather) {
            return `Weather data for ${location} is not available.`;
          }

          return `The current weather in ${location} is ${weather[unit]}.`;
        },
      },
    },
  });
  return result.toAIStreamResponse();
};
